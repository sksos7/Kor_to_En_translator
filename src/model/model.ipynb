{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e438453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d972fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719684e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"kor-eng/kor.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49fcfd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "  w = w.lower().strip()\n",
    "\n",
    "  # 단어와 단어 뒤에 오는 구두점(.)사이에 공백을 생성합니다.\n",
    "  # 예시: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # 참고:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")을 제외한 모든 것을 공백으로 대체합니다.\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # 모델이 예측을 시작하거나 중단할 때를 알게 하기 위해서\n",
    "  # 문장에 start와 end 토큰을 추가합니다.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w\n",
    "\n",
    "def preprocess_sentence_kr(w):\n",
    "  w = w.strip()\n",
    "\n",
    "  # 단어와 단어 뒤에 오는 구두점(.)사이에 공백을 생성합니다.\n",
    "  # 예시: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # 참고:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  w = re.sub(r'[ |ㄱ-ㅎ|ㅏ-ㅣ]+', \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # 모델이 예측을 시작하거나 중단할 때를 알게 하기 위해서\n",
    "  # 문장에 start와 end 토큰을 추가합니다.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bae886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "<start> 너는 누구니 ? <end>\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "ko_sentence = u\"너는 누구니?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence_kr(ko_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a28df011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 문장에 있는 억양을 제거합니다.\n",
    "# 2. 불필요한 문자를 제거하여 문장을 정리합니다.\n",
    "# 3. 다음과 같은 형식으로 문장의 쌍을 반환합니다: [영어, 한글]\n",
    "\n",
    "def create_dataset(path, num_examples):\n",
    "  data = pd.read_csv(path, delimiter = \"\\t\")\n",
    "  data.columns = [\"en\", \"kor\", \"cc\"]\n",
    "  en = [preprocess_sentence(l) for l in data['en'][:num_examples]]\n",
    "  kr = [preprocess_sentence_kr(l) for l in data['kor'][:num_examples]]\n",
    "\n",
    "  # 다음과 같은 형식으로 문장의 쌍을 반환합니다: [영어, 한국어]\n",
    "  return en, kr # 이렇게 하면 한->영 번역이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a53ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman . <end>\n",
      "<start> 의심의 여지 없이 세상에는 어떤 남자이든 정확히 딱 알맞는 여자와 결혼하거나 그 반대의 상황이 존재하지 . 그런데 인간이 수백 명의 사람만 알고 지내는 사이가 될 기회를 갖는다고 생각해 보면 , 또 그 수백 명 중 열여 명 쯤 이하만 잘 알 수 있고 , 그리고 나서 그 열여 명 중에 한두 명만 친구가 될 수 있다면 , 그리고 또 만일 우리가 이 세상에 살고 있는 수백만 명의 사람들만 기억하고 있다면 , 딱 맞는 남자는 지구가 생겨난 이래로 딱 맞는 여자를 단 한번도 만난 적이 없을 수도 있을 거라는 사실을 쉽게 눈치챌 수 있을 거야 . <end>\n"
     ]
    }
   ],
   "source": [
    "en, kor = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(kor[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c160ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160fda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  # 전처리된 타겟 문장과 입력 문장 쌍을 생성합니다.\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "284acaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 17\n"
     ]
    }
   ],
   "source": [
    "# 언어 데이터셋을 아래의 크기로 제한하여 훈련과 검증을 수행합니다.\n",
    "num_examples = 3700\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# 타겟 텐서와 입력 텐서의 최대 길이를 계산합니다.\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "print(max_length_targ, max_length_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8244b514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2960 2960 740 740\n"
     ]
    }
   ],
   "source": [
    "# 훈련 집합과 검증 집합을 80대 20으로 분리합니다.\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# 훈련 집합과 검증 집합의 데이터 크기를 출력합니다.\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600ea24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac53889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "24 ----> 너\n",
      "144 ----> 진짜\n",
      "89 ----> 우리가\n",
      "799 ----> 도울\n",
      "12 ----> 수\n",
      "67 ----> 있을\n",
      "190 ----> 거라고\n",
      "74 ----> 생각해\n",
      "4 ----> ?\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "17 ----> do\n",
      "7 ----> you\n",
      "61 ----> really\n",
      "32 ----> think\n",
      "31 ----> we\n",
      "30 ----> can\n",
      "74 ----> help\n",
      "8 ----> ?\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf9438bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5490 2448\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)\n",
    "\n",
    "print(vocab_inp_size, vocab_tar_size)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e7a07a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 17]), TensorShape([64, 19]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cccc1f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e8d1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 17, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# 샘플 입력\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61957b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # 쿼리 은닉 상태(query hidden state)는 (batch_size, hidden size)쌍으로 이루어져 있습니다.\n",
    "    # query_with_time_axis은 (batch_size, 1, hidden size)쌍으로 이루어져 있습니다.\n",
    "    # values는 (batch_size, max_len, hidden size)쌍으로 이루어져 있습니다.\n",
    "    # 스코어(score)계산을 위해 덧셈을 수행하고자 시간 축을 확장하여 아래의 과정을 수행합니다.\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score는 (batch_size, max_length, 1)쌍으로 이루어져 있습니다.\n",
    "    # score를 self.V에 적용하기 때문에 마지막 축에 1을 얻습니다.\n",
    "    # self.V에 적용하기 전에 텐서는 (batch_size, max_length, units)쌍으로 이루어져 있습니다.\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights는 (batch_size, max_length, 1)쌍으로 이루어져 있습니다. \n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # 덧셈이후 컨텍스트 벡터(context_vector)는 (batch_size, hidden_size)쌍으로 이루어져 있습니다.\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1536994b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 17, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "158f2f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # 어텐션을 사용합니다.\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output는 (batch_size, max_length, hidden_size)쌍으로 이루어져 있습니다.\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # 임베딩층을 통과한 후 x는 (batch_size, 1, embedding_dim)쌍으로 이루어져 있습니다.\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # 컨텍스트 벡터와 임베딩 결과를 결합한 이후 x의 형태는 (batch_size, 1, embedding_dim + hidden_size)쌍으로 이루어져 있습니다.\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # 위에서 결합된 벡터를 GRU에 전달합니다.\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output은 (batch_size * 1, hidden_size)쌍으로 이루어져 있습니다.\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output은 (batch_size, vocab)쌍으로 이루어져 있습니다.\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8014571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 2448)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cb0958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f742f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af9e8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "# def train_step(inp, targ, enc_hidden):\n",
    "#   loss = 0\n",
    "\n",
    "#   with tf.GradientTape() as tape:\n",
    "#     enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "#     dec_hidden = enc_hidden\n",
    "\n",
    "#     dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "#     # 교사 강요(teacher forcing) - 다음 입력으로 타겟을 피딩(feeding)합니다.\n",
    "#     for t in range(1, targ.shape[1]):\n",
    "#       # enc_output를 디코더에 전달합니다.\n",
    "#       predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "#       loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "#       # 교사 강요(teacher forcing)를 사용합니다.\n",
    "#       dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "#   batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "#   variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "#   gradients = tape.gradient(loss, variables)\n",
    "\n",
    "#   optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "#   return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "317061dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 10\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#   start = time.time()\n",
    "\n",
    "#   enc_hidden = encoder.initialize_hidden_state()\n",
    "#   total_loss = 0\n",
    "\n",
    "#   for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "#     batch_loss = train_step(inp, targ, enc_hidden)\n",
    "#     total_loss += batch_loss\n",
    "\n",
    "#     if batch % 100 == 0:\n",
    "#       print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "#                                                    batch,\n",
    "#                                                    batch_loss.numpy()))\n",
    "#   # 에포크가 2번 실행될때마다 모델 저장 (체크포인트)\n",
    "#   if (epoch + 1) % 2 == 0:\n",
    "#     checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "#   print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "#                                       total_loss / steps_per_epoch))\n",
    "#   print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62c633f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence_kr(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # 나중에 어텐션 가중치를 시각화하기 위해 어텐션 가중치를 저장합니다.\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # 예측된 ID를 모델에 다시 피드합니다.\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "003719f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 가중치를 그리기 위한 함수입니다.\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "546d714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3418385b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./training_checkpoints\\ckpt-2\n"
     ]
    }
   ],
   "source": [
    "# checkpoint_dir내에 있는 최근 체크포인트(checkpoint)를 복원합니다.\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "print(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec5c4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc\n",
    "font_path = \"C:/Windows/Fonts/NGULIM.TTF\"\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fe7f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 계속 시도해 . <end>\n",
      "Predicted translation: keep trying . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('계속 시도해.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
